import paddlex as pdx
from paddlex import transforms as T

# 下载和解压昆虫检测数据集
# dataset = "https://bj.bcebos.com/paddlex/datasets/insect_det.tar.gz"
# pdx.utils.download_and_decompress(dataset, path="./")

# 定义训练和验证时的transforms
# API说明：https://github.com/PaddlePaddle/PaddleX/blob/develop/docs/apis/transforms/transforms.md
train_transforms = T.Compose(
    [
        T.MixupImage(mixup_epoch=-1),
        T.RandomDistort(),
        T.RandomExpand(im_padding_value=[123.675, 116.28, 103.53]),
        T.RandomCrop(),
        T.RandomHorizontalFlip(),
        T.BatchRandomResize(
            target_sizes=[192, 224, 256, 288, 320, 352, 384, 416, 448, 480, 512],
            interp="RANDOM",
        ),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)

eval_transforms = T.Compose(
    [
        T.Resize(target_size=320, interp="CUBIC"),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)

# 定义训练和验证所用的数据集
# API说明：https://github.com/PaddlePaddle/PaddleX/blob/develop/docs/apis/datasets.md
# train_dataset = pdx.datasets.VOCDetection(
#     data_dir="insect_det",
#     file_list="insect_det/train_list.txt",
#     label_list="insect_det/labels.txt",
#     transforms=train_transforms,
#     shuffle=True,
# )
train_dataset = pdx.datasets.VOCDetection(
    data_dir="data/pascal",
    file_list="data/pascal/train_list.txt",
    label_list="data/pascal/labels.txt",
    transforms=train_transforms,
    shuffle=True,
)

eval_dataset = pdx.datasets.VOCDetection(
    data_dir="data/pascal",
    file_list="data/pascal/val_list.txt",
    label_list="data/pascal/labels.txt",
    transforms=eval_transforms,
    shuffle=False,
)

# 初始化模型，并进行训练
# 可使用VisualDL查看训练指标，参考https://github.com/PaddlePaddle/PaddleX/blob/develop/docs/visualdl.md
num_classes = len(train_dataset.labels)
model = pdx.det.PPYOLOTiny(num_classes=num_classes)

# API说明：https://github.com/PaddlePaddle/PaddleX/blob/develop/docs/apis/models/detection.md
# 各参数介绍与调整说明：https://github.com/PaddlePaddle/PaddleX/blob/develop/docs/parameters.md
model.train(
    num_epochs=550,
    train_dataset=train_dataset,
    train_batch_size=2,
    eval_dataset=eval_dataset,
    pretrain_weights="COCO",
    learning_rate=0.005,
    warmup_steps=1000,
    warmup_start_lr=0.0,
    lr_decay_epochs=[130, 540],
    lr_decay_gamma=0.5,
    save_interval_epochs=2,
    save_dir="output/shoe",
    use_vdl=True,
)
